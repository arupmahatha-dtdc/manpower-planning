{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hub_code</th>\n",
       "      <th>hub_name</th>\n",
       "      <th>region</th>\n",
       "      <th>zone</th>\n",
       "      <th>shift_slots</th>\n",
       "      <th>out_docs</th>\n",
       "      <th>out_non_docs</th>\n",
       "      <th>out_air</th>\n",
       "      <th>out_surface</th>\n",
       "      <th>out_ndx_out_vol</th>\n",
       "      <th>out_ndx_vol_wt</th>\n",
       "      <th>in_docs</th>\n",
       "      <th>in_non_docs</th>\n",
       "      <th>in_air</th>\n",
       "      <th>in_surface</th>\n",
       "      <th>in_ndx_out_vol</th>\n",
       "      <th>in_ndx_vol_wt</th>\n",
       "      <th>apex_branch</th>\n",
       "      <th>sorter</th>\n",
       "      <th>at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>12PM-8PM</td>\n",
       "      <td>103493</td>\n",
       "      <td>107050</td>\n",
       "      <td>31</td>\n",
       "      <td>210512</td>\n",
       "      <td>107050</td>\n",
       "      <td>231123.629</td>\n",
       "      <td>267556.0</td>\n",
       "      <td>170179.0</td>\n",
       "      <td>274728.0</td>\n",
       "      <td>163007.0</td>\n",
       "      <td>170179.0</td>\n",
       "      <td>347680.506</td>\n",
       "      <td>M10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>6AM-12PM</td>\n",
       "      <td>342787</td>\n",
       "      <td>278380</td>\n",
       "      <td>278329</td>\n",
       "      <td>342838</td>\n",
       "      <td>278380</td>\n",
       "      <td>590461.010</td>\n",
       "      <td>242605.0</td>\n",
       "      <td>269129.0</td>\n",
       "      <td>186118.0</td>\n",
       "      <td>325616.0</td>\n",
       "      <td>269129.0</td>\n",
       "      <td>613053.081</td>\n",
       "      <td>M10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>694312</td>\n",
       "      <td>776248</td>\n",
       "      <td>516588</td>\n",
       "      <td>953972</td>\n",
       "      <td>776248</td>\n",
       "      <td>1789246.125</td>\n",
       "      <td>633729.0</td>\n",
       "      <td>742536.0</td>\n",
       "      <td>201818.0</td>\n",
       "      <td>1174447.0</td>\n",
       "      <td>742536.0</td>\n",
       "      <td>1702423.691</td>\n",
       "      <td>M10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N05</td>\n",
       "      <td>DELHI SAMALKHA APEX</td>\n",
       "      <td>NORTH DELHI RO</td>\n",
       "      <td>North</td>\n",
       "      <td>12PM-8PM</td>\n",
       "      <td>454260</td>\n",
       "      <td>680168</td>\n",
       "      <td>263928</td>\n",
       "      <td>870500</td>\n",
       "      <td>680168</td>\n",
       "      <td>2428230.281</td>\n",
       "      <td>317662.0</td>\n",
       "      <td>439161.0</td>\n",
       "      <td>379856.0</td>\n",
       "      <td>376967.0</td>\n",
       "      <td>439161.0</td>\n",
       "      <td>1149262.525</td>\n",
       "      <td>N05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N05</td>\n",
       "      <td>DELHI SAMALKHA APEX</td>\n",
       "      <td>NORTH DELHI RO</td>\n",
       "      <td>North</td>\n",
       "      <td>6AM-12PM</td>\n",
       "      <td>486559</td>\n",
       "      <td>443275</td>\n",
       "      <td>378682</td>\n",
       "      <td>551152</td>\n",
       "      <td>443275</td>\n",
       "      <td>1070586.367</td>\n",
       "      <td>356932.0</td>\n",
       "      <td>512115.0</td>\n",
       "      <td>157278.0</td>\n",
       "      <td>711769.0</td>\n",
       "      <td>512115.0</td>\n",
       "      <td>1403783.931</td>\n",
       "      <td>N05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>R01</td>\n",
       "      <td>NAGPUR AIR APEX</td>\n",
       "      <td>NAGPUR RO</td>\n",
       "      <td>West</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>65896</td>\n",
       "      <td>24476</td>\n",
       "      <td>46028</td>\n",
       "      <td>44344</td>\n",
       "      <td>24476</td>\n",
       "      <td>44909.632</td>\n",
       "      <td>58073.0</td>\n",
       "      <td>24343.0</td>\n",
       "      <td>33974.0</td>\n",
       "      <td>48442.0</td>\n",
       "      <td>24343.0</td>\n",
       "      <td>45517.672</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>T02</td>\n",
       "      <td>RANCHI APEX</td>\n",
       "      <td>PATNA</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>11557</td>\n",
       "      <td>15805</td>\n",
       "      <td>280</td>\n",
       "      <td>27082</td>\n",
       "      <td>15805</td>\n",
       "      <td>79840.775</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2962.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>5704.603</td>\n",
       "      <td>T02</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>U43</td>\n",
       "      <td>LUCKNOW APEX</td>\n",
       "      <td>GHAZIABAD RO</td>\n",
       "      <td>North</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>111118</td>\n",
       "      <td>206985</td>\n",
       "      <td>15775</td>\n",
       "      <td>302328</td>\n",
       "      <td>206985</td>\n",
       "      <td>818433.904</td>\n",
       "      <td>69631.0</td>\n",
       "      <td>94881.0</td>\n",
       "      <td>31468.0</td>\n",
       "      <td>133044.0</td>\n",
       "      <td>94881.0</td>\n",
       "      <td>321320.868</td>\n",
       "      <td>U43</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>W53</td>\n",
       "      <td>BHUBANESWAR AIR APEX</td>\n",
       "      <td>BHUBANESHWAR</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>25111</td>\n",
       "      <td>17640</td>\n",
       "      <td>35949</td>\n",
       "      <td>6802</td>\n",
       "      <td>17640</td>\n",
       "      <td>39108.420</td>\n",
       "      <td>25043.0</td>\n",
       "      <td>17096.0</td>\n",
       "      <td>7426.0</td>\n",
       "      <td>34713.0</td>\n",
       "      <td>17096.0</td>\n",
       "      <td>37987.575</td>\n",
       "      <td>W53</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>X01</td>\n",
       "      <td>DHARAPUR APEX</td>\n",
       "      <td>GUWAHATI</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>35883</td>\n",
       "      <td>146944</td>\n",
       "      <td>14904</td>\n",
       "      <td>167923</td>\n",
       "      <td>146944</td>\n",
       "      <td>832066.219</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>27790.0</td>\n",
       "      <td>33834.0</td>\n",
       "      <td>9133.0</td>\n",
       "      <td>27790.0</td>\n",
       "      <td>90490.718</td>\n",
       "      <td>X01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hub_code              hub_name          region   zone shift_slots  \\\n",
       "0       M10  MUMBAI SAKINAKA APEX          MUMBAI   West    12PM-8PM   \n",
       "1       M10  MUMBAI SAKINAKA APEX          MUMBAI   West    6AM-12PM   \n",
       "2       M10  MUMBAI SAKINAKA APEX          MUMBAI   West     8PM-6AM   \n",
       "3       N05   DELHI SAMALKHA APEX  NORTH DELHI RO  North    12PM-8PM   \n",
       "4       N05   DELHI SAMALKHA APEX  NORTH DELHI RO  North    6AM-12PM   \n",
       "..      ...                   ...             ...    ...         ...   \n",
       "70      R01       NAGPUR AIR APEX       NAGPUR RO   West     8PM-6AM   \n",
       "71      T02           RANCHI APEX           PATNA   East     8PM-6AM   \n",
       "72      U43          LUCKNOW APEX    GHAZIABAD RO  North     8PM-6AM   \n",
       "73      W53  BHUBANESWAR AIR APEX    BHUBANESHWAR   East     8PM-6AM   \n",
       "74      X01         DHARAPUR APEX        GUWAHATI   East     8PM-6AM   \n",
       "\n",
       "    out_docs  out_non_docs  out_air  out_surface  out_ndx_out_vol  \\\n",
       "0     103493        107050       31       210512           107050   \n",
       "1     342787        278380   278329       342838           278380   \n",
       "2     694312        776248   516588       953972           776248   \n",
       "3     454260        680168   263928       870500           680168   \n",
       "4     486559        443275   378682       551152           443275   \n",
       "..       ...           ...      ...          ...              ...   \n",
       "70     65896         24476    46028        44344            24476   \n",
       "71     11557         15805      280        27082            15805   \n",
       "72    111118        206985    15775       302328           206985   \n",
       "73     25111         17640    35949         6802            17640   \n",
       "74     35883        146944    14904       167923           146944   \n",
       "\n",
       "    out_ndx_vol_wt   in_docs  in_non_docs    in_air  in_surface  \\\n",
       "0       231123.629  267556.0     170179.0  274728.0    163007.0   \n",
       "1       590461.010  242605.0     269129.0  186118.0    325616.0   \n",
       "2      1789246.125  633729.0     742536.0  201818.0   1174447.0   \n",
       "3      2428230.281  317662.0     439161.0  379856.0    376967.0   \n",
       "4      1070586.367  356932.0     512115.0  157278.0    711769.0   \n",
       "..             ...       ...          ...       ...         ...   \n",
       "70       44909.632   58073.0      24343.0   33974.0     48442.0   \n",
       "71       79840.775    1583.0       1439.0      60.0      2962.0   \n",
       "72      818433.904   69631.0      94881.0   31468.0    133044.0   \n",
       "73       39108.420   25043.0      17096.0    7426.0     34713.0   \n",
       "74      832066.219   15177.0      27790.0   33834.0      9133.0   \n",
       "\n",
       "    in_ndx_out_vol  in_ndx_vol_wt apex_branch  sorter  at  \n",
       "0         170179.0     347680.506         M10       1   7  \n",
       "1         269129.0     613053.081         M10       1   7  \n",
       "2         742536.0    1702423.691         M10       1   7  \n",
       "3         439161.0    1149262.525         N05       1   7  \n",
       "4         512115.0    1403783.931         N05       1   7  \n",
       "..             ...            ...         ...     ...  ..  \n",
       "70         24343.0      45517.672         R01       0   7  \n",
       "71          1439.0       5704.603         T02       0   7  \n",
       "72         94881.0     321320.868         U43       1   7  \n",
       "73         17096.0      37987.575         W53       0   7  \n",
       "74         27790.0      90490.718         X01       0   7  \n",
       "\n",
       "[75 rows x 20 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('hub_manpower_modelling.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values and their counts:\n",
      "in_docs: 6\n",
      "in_non_docs: 6\n",
      "in_air: 6\n",
      "in_surface: 6\n",
      "in_ndx_out_vol: 6\n",
      "in_ndx_vol_wt: 6\n",
      "\n",
      "Number of rows with any NaN values: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hub_code</th>\n",
       "      <th>hub_name</th>\n",
       "      <th>region</th>\n",
       "      <th>zone</th>\n",
       "      <th>shift_slots</th>\n",
       "      <th>out_docs</th>\n",
       "      <th>out_non_docs</th>\n",
       "      <th>out_air</th>\n",
       "      <th>out_surface</th>\n",
       "      <th>out_ndx_out_vol</th>\n",
       "      <th>out_ndx_vol_wt</th>\n",
       "      <th>in_docs</th>\n",
       "      <th>in_non_docs</th>\n",
       "      <th>in_air</th>\n",
       "      <th>in_surface</th>\n",
       "      <th>in_ndx_out_vol</th>\n",
       "      <th>in_ndx_vol_wt</th>\n",
       "      <th>apex_branch</th>\n",
       "      <th>sorter</th>\n",
       "      <th>at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>12PM-8PM</td>\n",
       "      <td>103493</td>\n",
       "      <td>107050</td>\n",
       "      <td>31</td>\n",
       "      <td>210512</td>\n",
       "      <td>107050</td>\n",
       "      <td>231123.629</td>\n",
       "      <td>267556.0</td>\n",
       "      <td>170179.0</td>\n",
       "      <td>274728.0</td>\n",
       "      <td>163007.0</td>\n",
       "      <td>170179.0</td>\n",
       "      <td>347680.506</td>\n",
       "      <td>M10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>6AM-12PM</td>\n",
       "      <td>342787</td>\n",
       "      <td>278380</td>\n",
       "      <td>278329</td>\n",
       "      <td>342838</td>\n",
       "      <td>278380</td>\n",
       "      <td>590461.010</td>\n",
       "      <td>242605.0</td>\n",
       "      <td>269129.0</td>\n",
       "      <td>186118.0</td>\n",
       "      <td>325616.0</td>\n",
       "      <td>269129.0</td>\n",
       "      <td>613053.081</td>\n",
       "      <td>M10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>694312</td>\n",
       "      <td>776248</td>\n",
       "      <td>516588</td>\n",
       "      <td>953972</td>\n",
       "      <td>776248</td>\n",
       "      <td>1789246.125</td>\n",
       "      <td>633729.0</td>\n",
       "      <td>742536.0</td>\n",
       "      <td>201818.0</td>\n",
       "      <td>1174447.0</td>\n",
       "      <td>742536.0</td>\n",
       "      <td>1702423.691</td>\n",
       "      <td>M10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N05</td>\n",
       "      <td>DELHI SAMALKHA APEX</td>\n",
       "      <td>NORTH DELHI RO</td>\n",
       "      <td>North</td>\n",
       "      <td>12PM-8PM</td>\n",
       "      <td>454260</td>\n",
       "      <td>680168</td>\n",
       "      <td>263928</td>\n",
       "      <td>870500</td>\n",
       "      <td>680168</td>\n",
       "      <td>2428230.281</td>\n",
       "      <td>317662.0</td>\n",
       "      <td>439161.0</td>\n",
       "      <td>379856.0</td>\n",
       "      <td>376967.0</td>\n",
       "      <td>439161.0</td>\n",
       "      <td>1149262.525</td>\n",
       "      <td>N05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N05</td>\n",
       "      <td>DELHI SAMALKHA APEX</td>\n",
       "      <td>NORTH DELHI RO</td>\n",
       "      <td>North</td>\n",
       "      <td>6AM-12PM</td>\n",
       "      <td>486559</td>\n",
       "      <td>443275</td>\n",
       "      <td>378682</td>\n",
       "      <td>551152</td>\n",
       "      <td>443275</td>\n",
       "      <td>1070586.367</td>\n",
       "      <td>356932.0</td>\n",
       "      <td>512115.0</td>\n",
       "      <td>157278.0</td>\n",
       "      <td>711769.0</td>\n",
       "      <td>512115.0</td>\n",
       "      <td>1403783.931</td>\n",
       "      <td>N05</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>R01</td>\n",
       "      <td>NAGPUR AIR APEX</td>\n",
       "      <td>NAGPUR RO</td>\n",
       "      <td>West</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>65896</td>\n",
       "      <td>24476</td>\n",
       "      <td>46028</td>\n",
       "      <td>44344</td>\n",
       "      <td>24476</td>\n",
       "      <td>44909.632</td>\n",
       "      <td>58073.0</td>\n",
       "      <td>24343.0</td>\n",
       "      <td>33974.0</td>\n",
       "      <td>48442.0</td>\n",
       "      <td>24343.0</td>\n",
       "      <td>45517.672</td>\n",
       "      <td>R01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>T02</td>\n",
       "      <td>RANCHI APEX</td>\n",
       "      <td>PATNA</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>11557</td>\n",
       "      <td>15805</td>\n",
       "      <td>280</td>\n",
       "      <td>27082</td>\n",
       "      <td>15805</td>\n",
       "      <td>79840.775</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2962.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>5704.603</td>\n",
       "      <td>T02</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>U43</td>\n",
       "      <td>LUCKNOW APEX</td>\n",
       "      <td>GHAZIABAD RO</td>\n",
       "      <td>North</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>111118</td>\n",
       "      <td>206985</td>\n",
       "      <td>15775</td>\n",
       "      <td>302328</td>\n",
       "      <td>206985</td>\n",
       "      <td>818433.904</td>\n",
       "      <td>69631.0</td>\n",
       "      <td>94881.0</td>\n",
       "      <td>31468.0</td>\n",
       "      <td>133044.0</td>\n",
       "      <td>94881.0</td>\n",
       "      <td>321320.868</td>\n",
       "      <td>U43</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>W53</td>\n",
       "      <td>BHUBANESWAR AIR APEX</td>\n",
       "      <td>BHUBANESHWAR</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>25111</td>\n",
       "      <td>17640</td>\n",
       "      <td>35949</td>\n",
       "      <td>6802</td>\n",
       "      <td>17640</td>\n",
       "      <td>39108.420</td>\n",
       "      <td>25043.0</td>\n",
       "      <td>17096.0</td>\n",
       "      <td>7426.0</td>\n",
       "      <td>34713.0</td>\n",
       "      <td>17096.0</td>\n",
       "      <td>37987.575</td>\n",
       "      <td>W53</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>X01</td>\n",
       "      <td>DHARAPUR APEX</td>\n",
       "      <td>GUWAHATI</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>35883</td>\n",
       "      <td>146944</td>\n",
       "      <td>14904</td>\n",
       "      <td>167923</td>\n",
       "      <td>146944</td>\n",
       "      <td>832066.219</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>27790.0</td>\n",
       "      <td>33834.0</td>\n",
       "      <td>9133.0</td>\n",
       "      <td>27790.0</td>\n",
       "      <td>90490.718</td>\n",
       "      <td>X01</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hub_code              hub_name          region   zone shift_slots  \\\n",
       "0       M10  MUMBAI SAKINAKA APEX          MUMBAI   West    12PM-8PM   \n",
       "1       M10  MUMBAI SAKINAKA APEX          MUMBAI   West    6AM-12PM   \n",
       "2       M10  MUMBAI SAKINAKA APEX          MUMBAI   West     8PM-6AM   \n",
       "3       N05   DELHI SAMALKHA APEX  NORTH DELHI RO  North    12PM-8PM   \n",
       "4       N05   DELHI SAMALKHA APEX  NORTH DELHI RO  North    6AM-12PM   \n",
       "..      ...                   ...             ...    ...         ...   \n",
       "70      R01       NAGPUR AIR APEX       NAGPUR RO   West     8PM-6AM   \n",
       "71      T02           RANCHI APEX           PATNA   East     8PM-6AM   \n",
       "72      U43          LUCKNOW APEX    GHAZIABAD RO  North     8PM-6AM   \n",
       "73      W53  BHUBANESWAR AIR APEX    BHUBANESHWAR   East     8PM-6AM   \n",
       "74      X01         DHARAPUR APEX        GUWAHATI   East     8PM-6AM   \n",
       "\n",
       "    out_docs  out_non_docs  out_air  out_surface  out_ndx_out_vol  \\\n",
       "0     103493        107050       31       210512           107050   \n",
       "1     342787        278380   278329       342838           278380   \n",
       "2     694312        776248   516588       953972           776248   \n",
       "3     454260        680168   263928       870500           680168   \n",
       "4     486559        443275   378682       551152           443275   \n",
       "..       ...           ...      ...          ...              ...   \n",
       "70     65896         24476    46028        44344            24476   \n",
       "71     11557         15805      280        27082            15805   \n",
       "72    111118        206985    15775       302328           206985   \n",
       "73     25111         17640    35949         6802            17640   \n",
       "74     35883        146944    14904       167923           146944   \n",
       "\n",
       "    out_ndx_vol_wt   in_docs  in_non_docs    in_air  in_surface  \\\n",
       "0       231123.629  267556.0     170179.0  274728.0    163007.0   \n",
       "1       590461.010  242605.0     269129.0  186118.0    325616.0   \n",
       "2      1789246.125  633729.0     742536.0  201818.0   1174447.0   \n",
       "3      2428230.281  317662.0     439161.0  379856.0    376967.0   \n",
       "4      1070586.367  356932.0     512115.0  157278.0    711769.0   \n",
       "..             ...       ...          ...       ...         ...   \n",
       "70       44909.632   58073.0      24343.0   33974.0     48442.0   \n",
       "71       79840.775    1583.0       1439.0      60.0      2962.0   \n",
       "72      818433.904   69631.0      94881.0   31468.0    133044.0   \n",
       "73       39108.420   25043.0      17096.0    7426.0     34713.0   \n",
       "74      832066.219   15177.0      27790.0   33834.0      9133.0   \n",
       "\n",
       "    in_ndx_out_vol  in_ndx_vol_wt apex_branch  sorter  at  \n",
       "0         170179.0     347680.506         M10       1   7  \n",
       "1         269129.0     613053.081         M10       1   7  \n",
       "2         742536.0    1702423.691         M10       1   7  \n",
       "3         439161.0    1149262.525         N05       1   7  \n",
       "4         512115.0    1403783.931         N05       1   7  \n",
       "..             ...            ...         ...     ...  ..  \n",
       "70         24343.0      45517.672         R01       0   7  \n",
       "71          1439.0       5704.603         T02       0   7  \n",
       "72         94881.0     321320.868         U43       1   7  \n",
       "73         17096.0      37987.575         W53       0   7  \n",
       "74         27790.0      90490.718         X01       0   7  \n",
       "\n",
       "[69 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print column names and number of NaN values for each column with any NaN values\n",
    "nan_counts = df.isna().sum()\n",
    "cols_with_nan = nan_counts[nan_counts > 0]\n",
    "num_rows_with_nan = df.isna().any(axis=1).sum()\n",
    "\n",
    "if not cols_with_nan.empty:\n",
    "    print(\"Columns with NaN values and their counts:\")\n",
    "    for col, count in cols_with_nan.items():\n",
    "        print(f\"{col}: {count}\")\n",
    "    print(f\"\\nNumber of rows with any NaN values: {num_rows_with_nan}\")\n",
    "else:\n",
    "    print(\"No columns have NaN values.\")\n",
    "    print(\"Number of rows with any NaN values: 0\")\n",
    "\n",
    "# Drop all rows with any NaN values\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def roundup(x, digits=0):\n",
    "    factor = 10 ** digits\n",
    "    return np.ceil(x * factor) / factor\n",
    "\n",
    "# CORRECTED formulas based on formulation.ipynb\n",
    "formulas = {\n",
    "    'in_avg_wt_cn': lambda row: row['in_ndx_vol_wt'] / row['in_ndx_out_vol'],\n",
    "    'out_avg_wt_cn': lambda row: row['out_ndx_vol_wt'] / row['out_ndx_out_vol'],\n",
    "    'packet': lambda row: max(row['in_docs'], row['out_docs']) / 15,\n",
    "    'bag_doc': lambda row: (max(row['in_docs'], row['out_docs']) / 15) / 15,\n",
    "    'vol_bag_non_doc': lambda row: max(row['in_ndx_out_vol'], row['out_ndx_out_vol']) / 13,\n",
    "    'wt_bag_non_doc': lambda row: max(row['in_ndx_vol_wt'], row['out_ndx_vol_wt']) / 25,\n",
    "    'out_per_day_docs': lambda row: roundup(row['out_docs'] / 25, 0),\n",
    "    'out_per_day_non_docs': lambda row: roundup(row['out_non_docs'] / 25, 0),\n",
    "    'out_per_day_air': lambda row: roundup(row['out_air'] / 25, 0),\n",
    "    'out_per_day_surface': lambda row: roundup(row['out_surface'] / 25, 0),\n",
    "    'out_per_day_ndx_out_vol': lambda row: roundup(row['out_ndx_out_vol'] / 25, 0),\n",
    "    'out_per_day_ndx_vol_wt': lambda row: roundup(row['out_ndx_vol_wt'] / 25, 0),\n",
    "    'in_per_day_docs': lambda row: roundup(row['in_docs'] / 25, 0),\n",
    "    'in_per_day_non_docs': lambda row: roundup(row['in_non_docs'] / 25, 0),\n",
    "    'in_per_day_air': lambda row: roundup(row['in_air'] / 25, 0),\n",
    "    'in_per_day_surface': lambda row: roundup(row['in_surface'] / 25, 0),\n",
    "    'in_per_day_ndx_out_vol': lambda row: roundup(row['in_ndx_out_vol'] / 25, 0),\n",
    "    'in_per_day_ndx_vol_wt': lambda row: roundup(row['in_ndx_vol_wt'] / 25, 0),\n",
    "    'per_day_ndx': lambda row: max(row['out_per_day_non_docs'], row['in_per_day_non_docs']),\n",
    "    'per_day_dox': lambda row: max(row['out_per_day_docs'], row['in_per_day_docs']),\n",
    "    'per_day_packet': lambda row: row['packet'] / 25,\n",
    "    'per_day_bag_doc': lambda row: row['bag_doc'] / 25,\n",
    "    'per_day_bag_non_doc': lambda row: max(row['vol_bag_non_doc'], row['wt_bag_non_doc']) / 25,\n",
    "    'per_day_air': lambda row: row['out_per_day_air'] / 12,\n",
    "    'cd_unit': lambda row: (row['per_day_bag_doc'] + row['per_day_bag_non_doc']) * 35 / 3600,\n",
    "    'with_sorter_sorter_unit': lambda row: 20.16 * row['per_day_ndx'] * 0.55 / 3600,\n",
    "    'with_sorter_non_cony': lambda row: (row['with_sorter_sorter_unit'] * 0.3 * 1.5) / 0.55,\n",
    "    'manual_sorting_units': lambda row: row['per_day_ndx'] * 31.1 / 3600,\n",
    "    'xray_unit': lambda row: row['per_day_air'] * 15 / 3600,\n",
    "    'air_unit': lambda row: row['per_day_air'] * 38 / 3600,\n",
    "    'surface_unit': lambda row: ((row['per_day_bag_doc'] + row['per_day_bag_non_doc']) - row['per_day_air']) * 38 / 3600,\n",
    "    'doc_unit': lambda row: (0.6 * row['per_day_dox'] * 10.02222222) / 3600,\n",
    "    'exception_han_unit': lambda row: 0.05 * 30 * row['per_day_ndx'] / 3600,\n",
    "    'skidder_unit': lambda row: 0.1 * (\n",
    "        row['cd_unit'] +\n",
    "        row['with_sorter_sorter_unit'] +\n",
    "        row['with_sorter_non_cony'] +\n",
    "        row['manual_sorting_units'] +\n",
    "        row['xray_unit'] +\n",
    "        row['air_unit'] +\n",
    "        row['surface_unit'] +\n",
    "        row['doc_unit'] +\n",
    "        row['exception_han_unit']\n",
    "    ),\n",
    "    'total': lambda row: 1.2 * (\n",
    "        row['cd_unit'] +\n",
    "        row['with_sorter_sorter_unit'] +\n",
    "        row['with_sorter_non_cony'] +\n",
    "        row['manual_sorting_units'] +\n",
    "        row['skidder_unit'] +\n",
    "        row['xray_unit'] +\n",
    "        row['air_unit'] +\n",
    "        row['surface_unit'] +\n",
    "        row['doc_unit'] +\n",
    "        row['exception_han_unit'] -\n",
    "        row['manual_sorting_units']\n",
    "    ),\n",
    "    'manpower_in_units_cd_unit': lambda row: roundup(row['cd_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_with_sorter_sorter_unit': lambda row: roundup(row['with_sorter_sorter_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_with_sorter_non_cony': lambda row: roundup(row['with_sorter_non_cony'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_with_no_sorter_manual_sorting_units': lambda row: roundup(row['manual_sorting_units'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_skidder_unit': lambda row: roundup(row['skidder_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_xray_unit': lambda row: roundup(row['xray_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_air_unit': lambda row: roundup(row['air_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_surface_unit': lambda row: roundup(row['surface_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_doc_unit': lambda row: roundup(row['doc_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_in_units_exception_han_unit': lambda row: roundup(row['exception_han_unit'] * 1.25 / row['at'], 0),\n",
    "    'manpower_with_sorter': lambda row: (\n",
    "        row['manpower_in_units_cd_unit'] +\n",
    "        row['manpower_in_units_with_sorter_sorter_unit'] +\n",
    "        row['manpower_in_units_with_sorter_non_cony'] +\n",
    "        row['manpower_in_units_with_no_sorter_manual_sorting_units'] +\n",
    "        row['manpower_in_units_skidder_unit'] +\n",
    "        row['manpower_in_units_xray_unit'] +\n",
    "        row['manpower_in_units_air_unit'] +\n",
    "        row['manpower_in_units_surface_unit'] +\n",
    "        row['manpower_in_units_doc_unit'] +\n",
    "        row['manpower_in_units_exception_han_unit'] -\n",
    "        row['manpower_in_units_with_no_sorter_manual_sorting_units']\n",
    "    ),\n",
    "    'manpower_without_sorter': lambda row: (\n",
    "        row['manpower_in_units_cd_unit'] +\n",
    "        row['manpower_in_units_with_sorter_sorter_unit'] +\n",
    "        row['manpower_in_units_with_sorter_non_cony'] +\n",
    "        row['manpower_in_units_with_no_sorter_manual_sorting_units'] +\n",
    "        row['manpower_in_units_skidder_unit'] +\n",
    "        row['manpower_in_units_xray_unit'] +\n",
    "        row['manpower_in_units_air_unit'] +\n",
    "        row['manpower_in_units_surface_unit'] +\n",
    "        row['manpower_in_units_doc_unit'] +\n",
    "        row['manpower_in_units_exception_han_unit'] -\n",
    "        row['manpower_in_units_with_sorter_sorter_unit'] -\n",
    "        row['manpower_in_units_with_sorter_non_cony']\n",
    "    ),\n",
    "    # New columns as per instructions:\n",
    "    'per_day_dox_per_manpower_with_sorter': lambda row: row['per_day_dox'] / row['manpower_with_sorter'] if row['manpower_with_sorter'] != 0 else np.nan,\n",
    "    'per_day_ndx_per_manpower_with_sorter': lambda row: row['per_day_ndx'] / row['manpower_with_sorter'] if row['manpower_with_sorter'] != 0 else np.nan,\n",
    "    'per_day_dox_per_manpower_without_sorter': lambda row: row['per_day_dox'] / row['manpower_without_sorter'] if row['manpower_without_sorter'] != 0 else np.nan,\n",
    "    'per_day_ndx_per_manpower_without_sorter': lambda row: row['per_day_ndx'] / row['manpower_without_sorter'] if row['manpower_without_sorter'] != 0 else np.nan,\n",
    "}\n",
    "\n",
    "# To ensure dependencies are calculated in order, we use a list of keys in the correct order\n",
    "formula_keys = [\n",
    "    'in_avg_wt_cn',\n",
    "    'out_avg_wt_cn',\n",
    "    'packet',\n",
    "    'bag_doc',\n",
    "    'vol_bag_non_doc',\n",
    "    'wt_bag_non_doc',\n",
    "    'out_per_day_docs',\n",
    "    'out_per_day_non_docs',\n",
    "    'out_per_day_air',\n",
    "    'out_per_day_surface',\n",
    "    'out_per_day_ndx_out_vol',\n",
    "    'out_per_day_ndx_vol_wt',\n",
    "    'in_per_day_docs',\n",
    "    'in_per_day_non_docs',\n",
    "    'in_per_day_air',\n",
    "    'in_per_day_surface',\n",
    "    'in_per_day_ndx_out_vol',\n",
    "    'in_per_day_ndx_vol_wt',\n",
    "    'per_day_ndx',\n",
    "    'per_day_dox',\n",
    "    'per_day_packet',\n",
    "    'per_day_bag_doc',\n",
    "    'per_day_bag_non_doc',\n",
    "    'per_day_air',\n",
    "    'cd_unit',\n",
    "    'with_sorter_sorter_unit',\n",
    "    'with_sorter_non_cony',\n",
    "    'manual_sorting_units',\n",
    "    'xray_unit',\n",
    "    'air_unit',\n",
    "    'surface_unit',\n",
    "    'doc_unit',\n",
    "    'exception_han_unit',\n",
    "    'skidder_unit',\n",
    "    'total',\n",
    "    'manpower_in_units_cd_unit',\n",
    "    'manpower_in_units_with_sorter_sorter_unit',\n",
    "    'manpower_in_units_with_sorter_non_cony',\n",
    "    'manpower_in_units_with_no_sorter_manual_sorting_units',\n",
    "    'manpower_in_units_skidder_unit',\n",
    "    'manpower_in_units_xray_unit',\n",
    "    'manpower_in_units_air_unit',\n",
    "    'manpower_in_units_surface_unit',\n",
    "    'manpower_in_units_doc_unit',\n",
    "    'manpower_in_units_exception_han_unit',\n",
    "    'manpower_with_sorter',\n",
    "    'manpower_without_sorter',\n",
    "    # Add new columns at the end\n",
    "    'per_day_dox_per_manpower_with_sorter',\n",
    "    'per_day_ndx_per_manpower_with_sorter',\n",
    "    'per_day_dox_per_manpower_without_sorter',\n",
    "    'per_day_ndx_per_manpower_without_sorter'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
      "/var/folders/lw/mxt4vf712k5_lslhrjcqqj700000gn/T/ipykernel_29389/1354069223.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hub_code</th>\n",
       "      <th>hub_name</th>\n",
       "      <th>region</th>\n",
       "      <th>zone</th>\n",
       "      <th>shift_slots</th>\n",
       "      <th>out_docs</th>\n",
       "      <th>out_non_docs</th>\n",
       "      <th>out_air</th>\n",
       "      <th>out_surface</th>\n",
       "      <th>out_ndx_out_vol</th>\n",
       "      <th>...</th>\n",
       "      <th>manpower_in_units_air_unit</th>\n",
       "      <th>manpower_in_units_surface_unit</th>\n",
       "      <th>manpower_in_units_doc_unit</th>\n",
       "      <th>manpower_in_units_exception_han_unit</th>\n",
       "      <th>manpower_with_sorter</th>\n",
       "      <th>manpower_without_sorter</th>\n",
       "      <th>per_day_dox_per_manpower_with_sorter</th>\n",
       "      <th>per_day_ndx_per_manpower_with_sorter</th>\n",
       "      <th>per_day_dox_per_manpower_without_sorter</th>\n",
       "      <th>per_day_ndx_per_manpower_without_sorter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>12PM-8PM</td>\n",
       "      <td>103493</td>\n",
       "      <td>107050</td>\n",
       "      <td>31</td>\n",
       "      <td>210512</td>\n",
       "      <td>107050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>486.500000</td>\n",
       "      <td>309.454545</td>\n",
       "      <td>428.120000</td>\n",
       "      <td>272.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>6AM-12PM</td>\n",
       "      <td>342787</td>\n",
       "      <td>278380</td>\n",
       "      <td>278329</td>\n",
       "      <td>342838</td>\n",
       "      <td>278380</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>472.827586</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>403.294118</td>\n",
       "      <td>327.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M10</td>\n",
       "      <td>MUMBAI SAKINAKA APEX</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>West</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>694312</td>\n",
       "      <td>776248</td>\n",
       "      <td>516588</td>\n",
       "      <td>953972</td>\n",
       "      <td>776248</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>396.757143</td>\n",
       "      <td>443.571429</td>\n",
       "      <td>322.941860</td>\n",
       "      <td>361.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N05</td>\n",
       "      <td>DELHI SAMALKHA APEX</td>\n",
       "      <td>NORTH DELHI RO</td>\n",
       "      <td>North</td>\n",
       "      <td>12PM-8PM</td>\n",
       "      <td>454260</td>\n",
       "      <td>680168</td>\n",
       "      <td>263928</td>\n",
       "      <td>870500</td>\n",
       "      <td>680168</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>288.428571</td>\n",
       "      <td>431.857143</td>\n",
       "      <td>235.987013</td>\n",
       "      <td>353.337662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N05</td>\n",
       "      <td>DELHI SAMALKHA APEX</td>\n",
       "      <td>NORTH DELHI RO</td>\n",
       "      <td>North</td>\n",
       "      <td>6AM-12PM</td>\n",
       "      <td>486559</td>\n",
       "      <td>443275</td>\n",
       "      <td>378682</td>\n",
       "      <td>551152</td>\n",
       "      <td>443275</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>397.204082</td>\n",
       "      <td>418.061224</td>\n",
       "      <td>329.881356</td>\n",
       "      <td>347.203390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>R01</td>\n",
       "      <td>NAGPUR AIR APEX</td>\n",
       "      <td>NAGPUR RO</td>\n",
       "      <td>West</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>65896</td>\n",
       "      <td>24476</td>\n",
       "      <td>46028</td>\n",
       "      <td>44344</td>\n",
       "      <td>24476</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>329.500000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>329.500000</td>\n",
       "      <td>122.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>T02</td>\n",
       "      <td>RANCHI APEX</td>\n",
       "      <td>PATNA</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>11557</td>\n",
       "      <td>15805</td>\n",
       "      <td>280</td>\n",
       "      <td>27082</td>\n",
       "      <td>15805</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.444444</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>57.875000</td>\n",
       "      <td>79.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>U43</td>\n",
       "      <td>LUCKNOW APEX</td>\n",
       "      <td>GHAZIABAD RO</td>\n",
       "      <td>North</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>111118</td>\n",
       "      <td>206985</td>\n",
       "      <td>15775</td>\n",
       "      <td>302328</td>\n",
       "      <td>206985</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>193.260870</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>164.629630</td>\n",
       "      <td>306.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>W53</td>\n",
       "      <td>BHUBANESWAR AIR APEX</td>\n",
       "      <td>BHUBANESHWAR</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>25111</td>\n",
       "      <td>17640</td>\n",
       "      <td>35949</td>\n",
       "      <td>6802</td>\n",
       "      <td>17640</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>125.625000</td>\n",
       "      <td>88.250000</td>\n",
       "      <td>125.625000</td>\n",
       "      <td>88.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>X01</td>\n",
       "      <td>DHARAPUR APEX</td>\n",
       "      <td>GUWAHATI</td>\n",
       "      <td>East</td>\n",
       "      <td>8PM-6AM</td>\n",
       "      <td>35883</td>\n",
       "      <td>146944</td>\n",
       "      <td>14904</td>\n",
       "      <td>167923</td>\n",
       "      <td>146944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>293.900000</td>\n",
       "      <td>62.434783</td>\n",
       "      <td>255.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hub_code              hub_name          region   zone shift_slots  \\\n",
       "0       M10  MUMBAI SAKINAKA APEX          MUMBAI   West    12PM-8PM   \n",
       "1       M10  MUMBAI SAKINAKA APEX          MUMBAI   West    6AM-12PM   \n",
       "2       M10  MUMBAI SAKINAKA APEX          MUMBAI   West     8PM-6AM   \n",
       "3       N05   DELHI SAMALKHA APEX  NORTH DELHI RO  North    12PM-8PM   \n",
       "4       N05   DELHI SAMALKHA APEX  NORTH DELHI RO  North    6AM-12PM   \n",
       "..      ...                   ...             ...    ...         ...   \n",
       "70      R01       NAGPUR AIR APEX       NAGPUR RO   West     8PM-6AM   \n",
       "71      T02           RANCHI APEX           PATNA   East     8PM-6AM   \n",
       "72      U43          LUCKNOW APEX    GHAZIABAD RO  North     8PM-6AM   \n",
       "73      W53  BHUBANESWAR AIR APEX    BHUBANESHWAR   East     8PM-6AM   \n",
       "74      X01         DHARAPUR APEX        GUWAHATI   East     8PM-6AM   \n",
       "\n",
       "    out_docs  out_non_docs  out_air  out_surface  out_ndx_out_vol  ...  \\\n",
       "0     103493        107050       31       210512           107050  ...   \n",
       "1     342787        278380   278329       342838           278380  ...   \n",
       "2     694312        776248   516588       953972           776248  ...   \n",
       "3     454260        680168   263928       870500           680168  ...   \n",
       "4     486559        443275   378682       551152           443275  ...   \n",
       "..       ...           ...      ...          ...              ...  ...   \n",
       "70     65896         24476    46028        44344            24476  ...   \n",
       "71     11557         15805      280        27082            15805  ...   \n",
       "72    111118        206985    15775       302328           206985  ...   \n",
       "73     25111         17640    35949         6802            17640  ...   \n",
       "74     35883        146944    14904       167923           146944  ...   \n",
       "\n",
       "    manpower_in_units_air_unit  manpower_in_units_surface_unit  \\\n",
       "0                          1.0                             2.0   \n",
       "1                          2.0                             1.0   \n",
       "2                          4.0                             3.0   \n",
       "3                          2.0                             6.0   \n",
       "4                          3.0                             3.0   \n",
       "..                         ...                             ...   \n",
       "70                         1.0                            -0.0   \n",
       "71                         1.0                             1.0   \n",
       "72                         1.0                             3.0   \n",
       "73                         1.0                            -0.0   \n",
       "74                         1.0                             3.0   \n",
       "\n",
       "    manpower_in_units_doc_unit  manpower_in_units_exception_han_unit  \\\n",
       "0                          4.0                                   1.0   \n",
       "1                          5.0                                   1.0   \n",
       "2                          9.0                                   3.0   \n",
       "3                          6.0                                   3.0   \n",
       "4                          6.0                                   2.0   \n",
       "..                         ...                                   ...   \n",
       "70                         1.0                                   1.0   \n",
       "71                         1.0                                   1.0   \n",
       "72                         2.0                                   1.0   \n",
       "73                         1.0                                   1.0   \n",
       "74                         1.0                                   1.0   \n",
       "\n",
       "    manpower_with_sorter  manpower_without_sorter  \\\n",
       "0                   22.0                     25.0   \n",
       "1                   29.0                     34.0   \n",
       "2                   70.0                     86.0   \n",
       "3                   63.0                     77.0   \n",
       "4                   49.0                     59.0   \n",
       "..                   ...                      ...   \n",
       "70                   8.0                      8.0   \n",
       "71                   9.0                      8.0   \n",
       "72                  23.0                     27.0   \n",
       "73                   8.0                      8.0   \n",
       "74                  20.0                     23.0   \n",
       "\n",
       "    per_day_dox_per_manpower_with_sorter per_day_ndx_per_manpower_with_sorter  \\\n",
       "0                             486.500000                           309.454545   \n",
       "1                             472.827586                           384.000000   \n",
       "2                             396.757143                           443.571429   \n",
       "3                             288.428571                           431.857143   \n",
       "4                             397.204082                           418.061224   \n",
       "..                                   ...                                  ...   \n",
       "70                            329.500000                           122.500000   \n",
       "71                             51.444444                            70.333333   \n",
       "72                            193.260870                           360.000000   \n",
       "73                            125.625000                            88.250000   \n",
       "74                             71.800000                           293.900000   \n",
       "\n",
       "    per_day_dox_per_manpower_without_sorter  \\\n",
       "0                                428.120000   \n",
       "1                                403.294118   \n",
       "2                                322.941860   \n",
       "3                                235.987013   \n",
       "4                                329.881356   \n",
       "..                                      ...   \n",
       "70                               329.500000   \n",
       "71                                57.875000   \n",
       "72                               164.629630   \n",
       "73                               125.625000   \n",
       "74                                62.434783   \n",
       "\n",
       "    per_day_ndx_per_manpower_without_sorter  \n",
       "0                                272.320000  \n",
       "1                                327.529412  \n",
       "2                                361.046512  \n",
       "3                                353.337662  \n",
       "4                                347.203390  \n",
       "..                                      ...  \n",
       "70                               122.500000  \n",
       "71                                79.125000  \n",
       "72                               306.666667  \n",
       "73                                88.250000  \n",
       "74                               255.565217  \n",
       "\n",
       "[69 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply formulas in order, row-wise, so dependencies are resolved\n",
    "for key in formula_keys:\n",
    "    df[key] = df.apply(lambda row: formulas[key](row), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. Identify categorical columns (object or category dtype, or low unique count)\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object' or df[col].dtype.name == 'category']\n",
    "for col in df.columns:\n",
    "    if col not in cat_cols and df[col].nunique() < 10 and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "        cat_cols.append(col)\n",
    "cat_cols = list(set(cat_cols))\n",
    "\n",
    "# 2. Identify input variables, EXCLUDING 'sorter' and 'at', but INCLUDING manpower columns\n",
    "all_formula_outputs = set(formulas.keys())\n",
    "manpower_cols = ['manpower_with_sorter', 'manpower_without_sorter']\n",
    "\n",
    "# Input variables: not formula outputs, numeric, not 'sorter', not 'at'\n",
    "input_vars = [\n",
    "    col for col in df.columns\n",
    "    if col not in all_formula_outputs\n",
    "    and pd.api.types.is_numeric_dtype(df[col])\n",
    "    and col.lower() not in [\"sorter\", \"at\"]\n",
    "]\n",
    "\n",
    "# Final analysis columns: input_vars + manpower columns (if present)\n",
    "analysis_numeric_cols = [col for col in input_vars] + [col for col in manpower_cols if col in df.columns]\n",
    "\n",
    "# 3. For each categorical column, create a folder and save summary statistics and plots\n",
    "os.makedirs(\"grouped_analysis\", exist_ok=True)\n",
    "\n",
    "for cat in cat_cols:\n",
    "    folder = os.path.join(\"grouped_analysis\", str(cat))\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    grouped = df.groupby(cat)[analysis_numeric_cols]\n",
    "\n",
    "    # Save summary statistics as CSVs (only for analysis_numeric_cols)\n",
    "    grouped.mean().to_csv(os.path.join(folder, \"mean.csv\"))\n",
    "    grouped.sum().to_csv(os.path.join(folder, \"sum.csv\"))\n",
    "    grouped.median().to_csv(os.path.join(folder, \"median.csv\"))\n",
    "    # Mode: handle possible empty mode\n",
    "    mode_df = grouped.agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    mode_df.to_csv(os.path.join(folder, \"mode.csv\"))\n",
    "\n",
    "    # 4. For each numeric column, save only a swarmplot\n",
    "    for num in analysis_numeric_cols:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.swarmplot(x=cat, y=num, data=df, size=5, alpha=0.7)\n",
    "        plt.title(f\"Swarmplot of {num} grouped by {cat}\")\n",
    "        plt.xlabel(cat)\n",
    "        plt.ylabel(num)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(folder, f\"swarmplot_{num}.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'apex_branch' and then by 'shift_slots', and analyze 'manpower_with_sorter' and 'manpower_without_sorter'\n",
    "\n",
    "manpower_cols_to_analyze = [\n",
    "    'manpower_with_sorter', \n",
    "    'manpower_without_sorter',\n",
    "    'per_day_dox_per_manpower_without_sorter', \n",
    "    'per_day_ndx_per_manpower_without_sorter'\n",
    "]\n",
    "\n",
    "# 1. Swarmplots for apex_branch\n",
    "apex_folder = os.path.join(\"grouped_analysis\", \"apex_branch\")\n",
    "os.makedirs(apex_folder, exist_ok=True)\n",
    "\n",
    "for col in manpower_cols_to_analyze:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.swarmplot(x='apex_branch', y=col, data=df, size=5, alpha=0.7)\n",
    "    plt.title(f\"Swarmplot of {col} grouped by apex_branch\")\n",
    "    plt.xlabel(\"apex_branch\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(apex_folder, f\"swarmplot_{col}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Also save mean, median, and mode CSVs for apex_branch\n",
    "grouped_apex = df.groupby('apex_branch')[manpower_cols_to_analyze]\n",
    "grouped_apex.mean().to_csv(os.path.join(apex_folder, \"mean.csv\"))\n",
    "grouped_apex.median().to_csv(os.path.join(apex_folder, \"median.csv\"))\n",
    "mode_apex = grouped_apex.agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "mode_apex.to_csv(os.path.join(apex_folder, \"mode.csv\"))\n",
    "\n",
    "# 2. Swarmplots for apex_branch and shift_slots\n",
    "apex_shift_folder = os.path.join(\"grouped_analysis\", \"apex_branch_shift_slots\")\n",
    "os.makedirs(apex_shift_folder, exist_ok=True)\n",
    "\n",
    "for col in manpower_cols_to_analyze:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.swarmplot(x='apex_branch', y=col, hue='shift_slots', data=df, size=5, alpha=0.7)\n",
    "    plt.title(f\"Swarmplot of {col} grouped by apex_branch and shift_slots\")\n",
    "    plt.xlabel(\"apex_branch\")\n",
    "    plt.ylabel(col)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='shift_slots', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(apex_shift_folder, f\"swarmplot_{col}_by_shift.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Also save mean, median, and mode CSVs for apex_branch and shift_slots\n",
    "grouped_apex_shift = df.groupby(['apex_branch', 'shift_slots'])[manpower_cols_to_analyze]\n",
    "grouped_apex_shift.mean().to_csv(os.path.join(apex_shift_folder, \"mean.csv\"))\n",
    "grouped_apex_shift.median().to_csv(os.path.join(apex_shift_folder, \"median.csv\"))\n",
    "mode_apex_shift = grouped_apex_shift.agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "mode_apex_shift.to_csv(os.path.join(apex_shift_folder, \"mode.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Create output folder for histograms\n",
    "hist_folder = \"numeric_histograms\"\n",
    "os.makedirs(hist_folder, exist_ok=True)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    df[col].plot(kind='hist', bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(hist_folder, f\"{col}_hist.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED dependencies for all formulas as per formulation.ipynb\n",
    "# Added new dependencies for per_day_dox_per_manpower_with_sorter, per_day_ndx_per_manpower_with_sorter, etc.\n",
    "\n",
    "dependencies = {\n",
    "    # Manpower units (all require their respective unit and 'at')\n",
    "    'manpower_in_units_cd_unit': ['cd_unit', 'at'],\n",
    "    'manpower_in_units_with_sorter_sorter_unit': ['with_sorter_sorter_unit', 'at'],\n",
    "    'manpower_in_units_with_sorter_non_cony': ['with_sorter_non_cony', 'at'],\n",
    "    'manpower_in_units_with_no_sorter_manual_sorting_units': ['manual_sorting_units', 'at'],\n",
    "    'manpower_in_units_skidder_unit': ['skidder_unit', 'at'],\n",
    "    'manpower_in_units_xray_unit': ['xray_unit', 'at'],\n",
    "    'manpower_in_units_air_unit': ['air_unit', 'at'],\n",
    "    'manpower_in_units_surface_unit': ['surface_unit', 'at'],\n",
    "    'manpower_in_units_doc_unit': ['doc_unit', 'at'],\n",
    "    'manpower_in_units_exception_han_unit': ['exception_han_unit', 'at'],\n",
    "\n",
    "    # Manpower sums (as per formulas)\n",
    "    'manpower_with_sorter': [\n",
    "        'manpower_in_units_cd_unit',\n",
    "        'manpower_in_units_with_sorter_sorter_unit',\n",
    "        'manpower_in_units_with_sorter_non_cony',\n",
    "        'manpower_in_units_with_no_sorter_manual_sorting_units',\n",
    "        'manpower_in_units_skidder_unit',\n",
    "        'manpower_in_units_xray_unit',\n",
    "        'manpower_in_units_air_unit',\n",
    "        'manpower_in_units_surface_unit',\n",
    "        'manpower_in_units_doc_unit',\n",
    "        'manpower_in_units_exception_han_unit',\n",
    "        # minus 'manpower_in_units_with_no_sorter_manual_sorting_units'\n",
    "    ],\n",
    "    'manpower_without_sorter': [\n",
    "        'manpower_in_units_cd_unit',\n",
    "        'manpower_in_units_with_sorter_sorter_unit',\n",
    "        'manpower_in_units_with_sorter_non_cony',\n",
    "        'manpower_in_units_with_no_sorter_manual_sorting_units',\n",
    "        'manpower_in_units_skidder_unit',\n",
    "        'manpower_in_units_xray_unit',\n",
    "        'manpower_in_units_air_unit',\n",
    "        'manpower_in_units_surface_unit',\n",
    "        'manpower_in_units_doc_unit',\n",
    "        'manpower_in_units_exception_han_unit',\n",
    "        # minus 'manpower_in_units_with_sorter_sorter_unit' and 'manpower_in_units_with_sorter_non_cony'\n",
    "    ],\n",
    "\n",
    "    # Units\n",
    "    'cd_unit': ['per_day_bag_doc', 'per_day_bag_non_doc'],\n",
    "    'with_sorter_sorter_unit': ['per_day_ndx'],\n",
    "    'with_sorter_non_cony': ['with_sorter_sorter_unit'],\n",
    "    'manual_sorting_units': ['per_day_ndx'],\n",
    "    'skidder_unit': [\n",
    "        'cd_unit',\n",
    "        'with_sorter_sorter_unit',\n",
    "        'with_sorter_non_cony',\n",
    "        'manual_sorting_units',\n",
    "        'xray_unit',\n",
    "        'air_unit',\n",
    "        'surface_unit',\n",
    "        'doc_unit',\n",
    "        'exception_han_unit'\n",
    "    ],\n",
    "    'xray_unit': ['per_day_air'],\n",
    "    'air_unit': ['per_day_air'],\n",
    "    'surface_unit': ['per_day_bag_doc', 'per_day_bag_non_doc', 'per_day_air'],\n",
    "    'doc_unit': ['per_day_dox'],\n",
    "    'exception_han_unit': ['per_day_ndx'],\n",
    "    'total': [\n",
    "        'cd_unit',\n",
    "        'with_sorter_sorter_unit',\n",
    "        'with_sorter_non_cony',\n",
    "        'manual_sorting_units',\n",
    "        'skidder_unit',\n",
    "        'xray_unit',\n",
    "        'air_unit',\n",
    "        'surface_unit',\n",
    "        'doc_unit',\n",
    "        'exception_han_unit'\n",
    "    ],\n",
    "\n",
    "    # Per day\n",
    "    'per_day_ndx': ['out_per_day_non_docs', 'in_per_day_non_docs'],\n",
    "    'per_day_dox': ['out_per_day_docs', 'in_per_day_docs'],\n",
    "    'per_day_packet': ['packet'],\n",
    "    'per_day_bag_doc': ['bag_doc'],\n",
    "    'per_day_bag_non_doc': ['vol_bag_non_doc', 'wt_bag_non_doc'],\n",
    "    'per_day_air': ['out_per_day_air'],\n",
    "\n",
    "    # Out/in per day\n",
    "    'out_per_day_docs': ['out_docs'],\n",
    "    'out_per_day_non_docs': ['out_non_docs'],\n",
    "    'out_per_day_air': ['out_air'],\n",
    "    'out_per_day_surface': ['out_surface'],\n",
    "    'out_per_day_ndx_out_vol': ['out_ndx_out_vol'],\n",
    "    'out_per_day_ndx_vol_wt': ['out_ndx_vol_wt'],\n",
    "    'in_per_day_docs': ['in_docs'],\n",
    "    'in_per_day_non_docs': ['in_non_docs'],\n",
    "    'in_per_day_air': ['in_air'],\n",
    "    'in_per_day_surface': ['in_surface'],\n",
    "    'in_per_day_ndx_out_vol': ['in_ndx_out_vol'],\n",
    "    'in_per_day_ndx_vol_wt': ['in_ndx_vol_wt'],\n",
    "\n",
    "    # Bag/vol/wt\n",
    "    'packet': ['in_docs', 'out_docs'],\n",
    "    'bag_doc': ['in_docs', 'out_docs'],\n",
    "    'vol_bag_non_doc': ['in_ndx_out_vol', 'out_ndx_out_vol'],\n",
    "    'wt_bag_non_doc': ['in_ndx_vol_wt', 'out_ndx_vol_wt'],\n",
    "\n",
    "    # Averages\n",
    "    'in_avg_wt_cn': ['in_ndx_vol_wt', 'in_ndx_out_vol'],\n",
    "    'out_avg_wt_cn': ['out_ndx_vol_wt', 'out_ndx_out_vol'],\n",
    "\n",
    "    # New: per_day_dox_per_manpower_with_sorter, per_day_ndx_per_manpower_with_sorter, etc.\n",
    "    'per_day_dox_per_manpower_with_sorter': ['per_day_dox', 'manpower_with_sorter'],\n",
    "    'per_day_ndx_per_manpower_with_sorter': ['per_day_ndx', 'manpower_with_sorter'],\n",
    "    'per_day_dox_per_manpower_without_sorter': ['per_day_dox', 'manpower_without_sorter'],\n",
    "    'per_day_ndx_per_manpower_without_sorter': ['per_day_ndx', 'manpower_without_sorter'],\n",
    "\n",
    "    # Base columns (leaf nodes)\n",
    "    # 'in_docs', 'out_docs', 'in_ndx_out_vol', 'out_ndx_out_vol', 'in_ndx_vol_wt', 'out_ndx_vol_wt', 'out_air', 'out_non_docs', 'out_docs', 'in_non_docs', 'in_air', 'in_surface', 'out_surface', 'at'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency graph saved to: /Users/arup/Documents/manpower-planning/dependency_graph.html\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "import tempfile\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "def build_dependency_graph(targets, dependencies):\n",
    "    G = nx.DiGraph()\n",
    "    visited = set()\n",
    "    def add_edges(var):\n",
    "        if var in visited:\n",
    "            return\n",
    "        visited.add(var)\n",
    "        if var in dependencies:\n",
    "            for dep in dependencies[var]:\n",
    "                G.add_edge(dep, var)\n",
    "                add_edges(dep)\n",
    "    for t in targets:\n",
    "        add_edges(t)\n",
    "    return G\n",
    "\n",
    "def hierarchy_pos_inverted(G, root=None, width=1., vert_gap=0.3, vert_loc=0, xcenter=0.5, pos=None, parent=None, level=0, level_dict=None):\n",
    "    \"\"\"\n",
    "    Like hierarchy_pos, but inverts the y axis so that targets are at the bottom,\n",
    "    and all nodes at the same depth are at the same y (vertical) position.\n",
    "    \"\"\"\n",
    "    if pos is None:\n",
    "        pos = {}\n",
    "    if level_dict is None:\n",
    "        level_dict = {}\n",
    "    if root is None:\n",
    "        if isinstance(G, nx.DiGraph):\n",
    "            root = [n for n,d in G.in_degree() if d==0][0]\n",
    "        else:\n",
    "            root = list(G.nodes)[0]\n",
    "    # Track nodes at each level for horizontal alignment\n",
    "    if level not in level_dict:\n",
    "        level_dict[level] = []\n",
    "    level_dict[level].append(root)\n",
    "    children = list(G.successors(root))\n",
    "    if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "        children = [c for c in children if c != parent]\n",
    "    if len(children)!=0:\n",
    "        dx = width/len(children)\n",
    "        nextx = xcenter - width/2 - dx/2\n",
    "        for child in children:\n",
    "            nextx += dx\n",
    "            pos, level_dict = hierarchy_pos_inverted(G,root=child, width=dx, vert_gap=vert_gap,\n",
    "                                vert_loc=vert_loc-vert_gap, xcenter=nextx, pos=pos, parent=root, level=level+1, level_dict=level_dict)\n",
    "    pos[root] = (xcenter, -level)  # Invert y: higher levels get more negative y\n",
    "    return pos, level_dict\n",
    "\n",
    "def prettify_label(label, max_line_length=18):\n",
    "    \"\"\"\n",
    "    Convert snake_case to words, and wrap to multiple lines if too long.\n",
    "    E.g. 'manpower_with_sorter_units_with_sorter' -> 'manpower with sorter\\nunits with sorter'\n",
    "    \"\"\"\n",
    "    # Replace underscores with spaces\n",
    "    label = label.replace('_', ' ')\n",
    "    # Optionally, capitalize first letter: label = label.capitalize()\n",
    "    # Wrap to multiple lines\n",
    "    lines = textwrap.wrap(label, width=max_line_length)\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def show_dependency_graph_in_browser_inverted(G, targets, save_html_path=\"dependency_graph.html\"):\n",
    "    # Use pyvis for interactive, zoomable, pan-able graph in browser\n",
    "    # Use a hierarchical layout for a tree-like, visually pleasant structure\n",
    "    # Make the graph more spaced and visually organized\n",
    "\n",
    "    # Reduced canvas size for less spacing (20% less)\n",
    "    net = Network(height=\"1920px\", width=\"3360px\", directed=True, notebook=False, bgcolor=\"#f4f6fa\", font_color=\"black\")\n",
    "\n",
    "    # Improved color palette for clarity and grouping\n",
    "    color_map = {}\n",
    "    for node in G.nodes():\n",
    "        if node in targets:\n",
    "            color_map[node] = '#e74c3c'  # red\n",
    "        elif node.startswith('manpower_in_units'):\n",
    "            color_map[node] = '#f39c12'  # bright orange\n",
    "        elif node.endswith('_unit'):\n",
    "            color_map[node] = '#8d5524'  # brown\n",
    "        elif node.startswith('per_day'):\n",
    "            color_map[node] = '#27ae60'  # green\n",
    "        elif node in ['in_docs', 'out_docs', 'in_ndx_out_vol', 'out_ndx_out_vol', 'in_ndx_vol_wt', 'out_ndx_vol_wt', 'out_air', 'out_non_docs', 'out_docs', 'in_non_docs', 'at']:\n",
    "            color_map[node] = '#2980b9'  # blue\n",
    "        else:\n",
    "            color_map[node] = '#8e44ad'  # purple\n",
    "\n",
    "    # Use hierarchy_pos_inverted to get a tree layout with targets at the bottom\n",
    "    try:\n",
    "        roots = [n for n, d in G.in_degree() if d == 0]\n",
    "        if roots:\n",
    "            # Reduce width and vert_gap by 20%\n",
    "            pos, level_dict = hierarchy_pos_inverted(G, root=roots[0], width=2.0, vert_gap=0.28)\n",
    "            # Now, for all nodes at the same level, align their y (vertical) position exactly\n",
    "            # Find all unique levels\n",
    "            level_to_y = {}\n",
    "            for node, (x, y) in pos.items():\n",
    "                level = -y  # since we inverted y\n",
    "                if level not in level_to_y:\n",
    "                    level_to_y[level] = []\n",
    "                level_to_y[level].append(node)\n",
    "            # Assign same y for all nodes at same level, and spread x evenly\n",
    "            for level, nodes in level_to_y.items():\n",
    "                n_nodes = len(nodes)\n",
    "                for i, node in enumerate(sorted(nodes)):\n",
    "                    # Reduce horizontal spread by 20%\n",
    "                    pos[node] = (0.8 * float(i+1)/(n_nodes+1) + 0.1, -level)\n",
    "        else:\n",
    "            pos = nx.spring_layout(G, k=2.0, seed=42)\n",
    "    except Exception:\n",
    "        pos = nx.spring_layout(G, k=2.0, seed=42)\n",
    "\n",
    "    # Defensive: If any node is missing from pos, assign it a default position\n",
    "    missing_nodes = [node for node in G.nodes() if node not in pos]\n",
    "    if missing_nodes:\n",
    "        y_min = min([y for (x, y) in pos.values()]) if pos else 0\n",
    "        for i, node in enumerate(missing_nodes):\n",
    "            pos[node] = (0.1 + 0.08*i, y_min - 0.24 - 0.08*i)\n",
    "\n",
    "    # Find all unique y (vertical) positions, sort them, and map to pixel coordinates\n",
    "    y_vals = sorted(set(y for (x, y) in pos.values()))\n",
    "    # Reduce vertical spread by 20% (was 3000, now 2400)\n",
    "    y_to_pixel = {y: int(2400 * (i/(len(y_vals)-1) if len(y_vals)>1 else 0.5)) for i, y in enumerate(y_vals)}\n",
    "    # Invert so that the largest y (i.e., the bottom, i.e., targets) is at the bottom of the canvas\n",
    "    for node in pos:\n",
    "        x, y = pos[node]\n",
    "        pos[node] = (x, y_to_pixel[y])\n",
    "\n",
    "    # Add nodes with much larger font, more border, shadow, and rectangular shape for clarity\n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        pretty_label = prettify_label(node, max_line_length=22)\n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=pretty_label,\n",
    "            color=color_map[node],\n",
    "            x=int(x*2400),  # More spread horizontally, but 20% less than before (was 3000)\n",
    "            y=int(y),       # Already mapped to pixel\n",
    "            physics=False,\n",
    "            shape=\"box\",  # <-- RECTANGULAR SHAPE\n",
    "            borderWidth=12,\n",
    "            borderWidthSelected=24,\n",
    "            shadow=True,\n",
    "            font={\n",
    "                \"size\": 64,  # Much larger font\n",
    "                \"face\": \"Arial\",\n",
    "                \"color\": \"#222\",\n",
    "                \"background\": \"#fff\",\n",
    "                \"strokeWidth\": 3,\n",
    "                \"strokeColor\": \"#333\",\n",
    "                \"multi\": True  # Allow newlines in label\n",
    "            },\n",
    "            widthConstraint={\"minimum\": 400, \"maximum\": 800},  # Make box much wider\n",
    "            heightConstraint={\"minimum\": 120, \"maximum\": 400}   # Make box much taller\n",
    "        )\n",
    "\n",
    "    # Add edges with color of the source node, and set smooth to False for straight lines\n",
    "    for src, dst in G.edges():\n",
    "        net.add_edge(\n",
    "            src, dst,\n",
    "            color=color_map.get(src, \"#7f8c8d\"),\n",
    "            width=5,\n",
    "            selectionWidth=22,  # <--- Make selected edges much more bold\n",
    "            arrows=\"to\",\n",
    "            smooth=False  # <--- Make edges straight\n",
    "        )\n",
    "\n",
    "    # Enhanced options for more spacing and better interaction, and custom highlight/blurring\n",
    "    net.set_options(\"\"\"\n",
    "    var options = {\n",
    "      \"layout\": {\n",
    "        \"hierarchical\": {\n",
    "          \"enabled\": true,\n",
    "          \"levelSeparation\": 760,\n",
    "          \"nodeSpacing\": 1440,\n",
    "          \"treeSpacing\": 2000,\n",
    "          \"direction\": \"DU\",\n",
    "          \"sortMethod\": \"directed\",\n",
    "          \"shakeTowards\": \"roots\"\n",
    "        }\n",
    "      },\n",
    "      \"nodes\": {\n",
    "        \"font\": {\n",
    "          \"size\": 64,\n",
    "          \"face\": \"Arial\",\n",
    "          \"color\": \"#222\",\n",
    "          \"background\": \"#fff\",\n",
    "          \"strokeWidth\": 3,\n",
    "          \"strokeColor\": \"#333\",\n",
    "          \"multi\": true\n",
    "        },\n",
    "        \"borderWidth\": 12,\n",
    "        \"borderWidthSelected\": 24,\n",
    "        \"shadow\": true,\n",
    "        \"shape\": \"box\",\n",
    "        \"widthConstraint\": {\n",
    "            \"minimum\": 400,\n",
    "            \"maximum\": 800\n",
    "        },\n",
    "        \"heightConstraint\": {\n",
    "            \"minimum\": 120,\n",
    "            \"maximum\": 400\n",
    "        }\n",
    "      },\n",
    "      \"edges\": {\n",
    "        \"arrows\": {\n",
    "          \"to\": {\n",
    "            \"enabled\": true,\n",
    "            \"scaleFactor\": 1.7\n",
    "          }\n",
    "        },\n",
    "        \"smooth\": false,\n",
    "        \"color\": {\n",
    "          \"inherit\": false\n",
    "        },\n",
    "        \"width\": 5,\n",
    "        \"selectionWidth\": 22\n",
    "      },\n",
    "      \"interaction\": {\n",
    "        \"navigationButtons\": true,\n",
    "        \"keyboard\": true,\n",
    "        \"zoomView\": true,\n",
    "        \"dragView\": true,\n",
    "        \"hover\": true,\n",
    "        \"multiselect\": true,\n",
    "        \"tooltipDelay\": 120\n",
    "      },\n",
    "      \"physics\": {\n",
    "        \"enabled\": false\n",
    "      }\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    # Add custom JS for blurring nodes by degree of distance from selected node\n",
    "    # This is injected into the HTML after pyvis writes it\n",
    "    custom_js = \"\"\"\n",
    "    <script type=\"text/javascript\">\n",
    "    function getNodeDegrees(network, nodeId, maxDepth=3) {\n",
    "        // BFS to get nodes by degree from nodeId\n",
    "        var degrees = {};\n",
    "        degrees[nodeId] = 0;\n",
    "        var visited = {};\n",
    "        visited[nodeId] = true;\n",
    "        var queue = [{id: nodeId, depth: 0}];\n",
    "        while (queue.length > 0) {\n",
    "            var current = queue.shift();\n",
    "            if (current.depth >= maxDepth) continue;\n",
    "            var neighbors = network.getConnectedNodes(current.id);\n",
    "            for (var i=0; i<neighbors.length; i++) {\n",
    "                var n = neighbors[i];\n",
    "                if (!visited[n]) {\n",
    "                    degrees[n] = current.depth + 1;\n",
    "                    visited[n] = true;\n",
    "                    queue.push({id: n, depth: current.depth + 1});\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return degrees;\n",
    "    }\n",
    "\n",
    "    function blurByDegree(network, nodeId) {\n",
    "        var allNodes = network.body.data.nodes.get();\n",
    "        var degrees = getNodeDegrees(network, nodeId, 3);\n",
    "        var updateNodes = [];\n",
    "        for (var i=0; i<allNodes.length; i++) {\n",
    "            var n = allNodes[i];\n",
    "            var deg = degrees.hasOwnProperty(n.id) ? degrees[n.id] : null;\n",
    "            var opacity = 1.0;\n",
    "            if (deg === null) {\n",
    "                opacity = 0.15;\n",
    "            } else if (deg === 1) {\n",
    "                opacity = 0.45;\n",
    "            } else if (deg === 2) {\n",
    "                opacity = 0.25;\n",
    "            } else if (deg === 3) {\n",
    "                opacity = 0.15;\n",
    "            }\n",
    "            // The selected node stays at full opacity\n",
    "            if (n.id == nodeId) opacity = 1.0;\n",
    "            updateNodes.push({\n",
    "                id: n.id,\n",
    "                color: {\n",
    "                    ...n.color,\n",
    "                    opacity: opacity\n",
    "                },\n",
    "                font: {\n",
    "                    ...n.font,\n",
    "                    color: \"rgba(34,34,34,\" + opacity + \")\"\n",
    "                }\n",
    "            });\n",
    "        }\n",
    "        network.body.data.nodes.update(updateNodes);\n",
    "\n",
    "        // Make connected edges much more bold\n",
    "        var allEdges = network.body.data.edges.get();\n",
    "        var updateEdges = [];\n",
    "        for (var i=0; i<allEdges.length; i++) {\n",
    "            var e = allEdges[i];\n",
    "            // If the edge is connected to the selected node, make it very bold\n",
    "            if (e.from == nodeId || e.to == nodeId) {\n",
    "                updateEdges.push({\n",
    "                    id: e.id,\n",
    "                    width: 22\n",
    "                });\n",
    "            } else {\n",
    "                updateEdges.push({\n",
    "                    id: e.id,\n",
    "                    width: 5\n",
    "                });\n",
    "            }\n",
    "        }\n",
    "        network.body.data.edges.update(updateEdges);\n",
    "    }\n",
    "\n",
    "    function resetBlur(network) {\n",
    "        var allNodes = network.body.data.nodes.get();\n",
    "        var updateNodes = [];\n",
    "        for (var i=0; i<allNodes.length; i++) {\n",
    "            var n = allNodes[i];\n",
    "            updateNodes.push({\n",
    "                id: n.id,\n",
    "                color: {\n",
    "                    ...n.color,\n",
    "                    opacity: 1.0\n",
    "                },\n",
    "                font: {\n",
    "                    ...n.font,\n",
    "                    color: \"#222\"\n",
    "                }\n",
    "            });\n",
    "        }\n",
    "        network.body.data.nodes.update(updateNodes);\n",
    "\n",
    "        // Reset all edge widths to normal\n",
    "        var allEdges = network.body.data.edges.get();\n",
    "        var updateEdges = [];\n",
    "        for (var i=0; i<allEdges.length; i++) {\n",
    "            var e = allEdges[i];\n",
    "            updateEdges.push({\n",
    "                id: e.id,\n",
    "                width: 5\n",
    "            });\n",
    "        }\n",
    "        network.body.data.edges.update(updateEdges);\n",
    "    }\n",
    "\n",
    "    // Wait for vis network to be ready\n",
    "    window.addEventListener(\"load\", function() {\n",
    "        // pyvis always uses 'network' as the variable name\n",
    "        if (typeof network !== \"undefined\") {\n",
    "            network.on(\"click\", function(params) {\n",
    "                if (params.nodes.length > 0) {\n",
    "                    blurByDegree(network, params.nodes[0]);\n",
    "                } else {\n",
    "                    resetBlur(network);\n",
    "                }\n",
    "            });\n",
    "            network.on(\"deselectNode\", function(params) {\n",
    "                resetBlur(network);\n",
    "            });\n",
    "        }\n",
    "    });\n",
    "    </script>\n",
    "    \"\"\"\n",
    "\n",
    "    # Save to a permanent HTML file and open in browser, injecting the custom JS for blurring\n",
    "    try:\n",
    "        # Save to a permanent HTML file for sharing\n",
    "        net.write_html(save_html_path)\n",
    "        # Inject custom JS for blurring\n",
    "        with open(save_html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            html = f.read()\n",
    "        # Insert before </body>\n",
    "        html = html.replace(\"</body>\", custom_js + \"\\n</body>\")\n",
    "        with open(save_html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "        # Also open in browser for immediate viewing\n",
    "        webbrowser.open(\"file://\" + os.path.abspath(save_html_path))\n",
    "        print(f\"Dependency graph saved to: {os.path.abspath(save_html_path)}\")\n",
    "    except AttributeError as e:\n",
    "        print(\"Could not render dependency graph due to an error in pyvis:\", e)\n",
    "        print(\"Please ensure your pyvis version is up to date and compatible.\")\n",
    "\n",
    "targets = ['manpower_with_sorter', 'manpower_without_sorter']\n",
    "G = build_dependency_graph(targets, dependencies)\n",
    "# Save to a permanent HTML file for sharing\n",
    "show_dependency_graph_in_browser_inverted(G, targets, save_html_path=\"dependency_graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All input/impacted variable pairs (no cutoff) as a matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>impacted_variable</th>\n",
       "      <th>air_unit</th>\n",
       "      <th>at</th>\n",
       "      <th>bag_doc</th>\n",
       "      <th>cd_unit</th>\n",
       "      <th>doc_unit</th>\n",
       "      <th>exception_han_unit</th>\n",
       "      <th>in_air</th>\n",
       "      <th>in_avg_wt_cn</th>\n",
       "      <th>in_docs</th>\n",
       "      <th>in_ndx_out_vol</th>\n",
       "      <th>...</th>\n",
       "      <th>per_day_packet</th>\n",
       "      <th>skidder_unit</th>\n",
       "      <th>sorter</th>\n",
       "      <th>surface_unit</th>\n",
       "      <th>total</th>\n",
       "      <th>vol_bag_non_doc</th>\n",
       "      <th>with_sorter_non_cony</th>\n",
       "      <th>with_sorter_sorter_unit</th>\n",
       "      <th>wt_bag_non_doc</th>\n",
       "      <th>xray_unit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_air</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_docs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_ndx_out_vol</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_ndx_vol_wt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_non_docs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>79.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_surface</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_air</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-38.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_docs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>78.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_ndx_out_vol</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>80.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_ndx_vol_wt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.6</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_non_docs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.4</td>\n",
       "      <td>80.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>out_surface</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "impacted_variable  air_unit   at  bag_doc  cd_unit  doc_unit  \\\n",
       "input_variable                                                 \n",
       "at                      0.0  NaN      0.0      0.0       0.0   \n",
       "in_air                  0.0  0.0      0.0      0.0       0.0   \n",
       "in_docs                 0.0  0.0     75.3      2.2      75.3   \n",
       "in_ndx_out_vol          0.0  0.0      0.0     29.8       0.0   \n",
       "in_ndx_vol_wt           0.0  0.0      0.0     71.4       0.0   \n",
       "in_non_docs             0.0  0.0      0.0      0.0       0.0   \n",
       "in_surface              0.0  0.0      0.0      0.0       0.0   \n",
       "out_air               100.0  0.0      0.0      0.0       0.0   \n",
       "out_docs                0.0  0.0     78.7      2.3      78.7   \n",
       "out_ndx_out_vol         0.0  0.0      0.0     26.5       0.0   \n",
       "out_ndx_vol_wt          0.0  0.0      0.0     81.8       0.0   \n",
       "out_non_docs            0.0  0.0      0.0      0.0       0.0   \n",
       "out_surface             0.0  0.0      0.0      0.0       0.0   \n",
       "\n",
       "impacted_variable  exception_han_unit  in_air  in_avg_wt_cn  in_docs  \\\n",
       "input_variable                                                         \n",
       "at                                0.0     0.0           0.0      0.0   \n",
       "in_air                            0.0     NaN           0.0      0.0   \n",
       "in_docs                           0.0     0.0           0.0      NaN   \n",
       "in_ndx_out_vol                    0.0     0.0         -50.0      0.0   \n",
       "in_ndx_vol_wt                     0.0     0.0         100.0      0.0   \n",
       "in_non_docs                      79.2     0.0           0.0      0.0   \n",
       "in_surface                        0.0     0.0           0.0      0.0   \n",
       "out_air                           0.0     0.0           0.0      0.0   \n",
       "out_docs                          0.0     0.0           0.0      0.0   \n",
       "out_ndx_out_vol                   0.0     0.0           0.0      0.0   \n",
       "out_ndx_vol_wt                    0.0     0.0           0.0      0.0   \n",
       "out_non_docs                     80.4     0.0           0.0      0.0   \n",
       "out_surface                       0.0     0.0           0.0      0.0   \n",
       "\n",
       "impacted_variable  in_ndx_out_vol  ...  per_day_packet  skidder_unit  sorter  \\\n",
       "input_variable                     ...                                         \n",
       "at                            0.0  ...             0.0           0.0     0.0   \n",
       "in_air                        0.0  ...             0.0           0.0     0.0   \n",
       "in_docs                       0.0  ...            75.3           5.5     0.0   \n",
       "in_ndx_out_vol                NaN  ...             0.0           3.8     0.0   \n",
       "in_ndx_vol_wt                 0.0  ...             0.0           9.2     0.0   \n",
       "in_non_docs                   0.0  ...             0.0          62.9     0.0   \n",
       "in_surface                    0.0  ...             0.0           0.0     0.0   \n",
       "out_air                       0.0  ...             0.0           0.7     0.0   \n",
       "out_docs                      0.0  ...            78.7           5.7     0.0   \n",
       "out_ndx_out_vol               0.0  ...             0.0           3.4     0.0   \n",
       "out_ndx_vol_wt                0.0  ...             0.0          10.5     0.0   \n",
       "out_non_docs                  0.0  ...             0.0          63.9     0.0   \n",
       "out_surface                   0.0  ...             0.0           0.0     0.0   \n",
       "\n",
       "impacted_variable  surface_unit  total  vol_bag_non_doc  with_sorter_non_cony  \\\n",
       "input_variable                                                                  \n",
       "at                          0.0    0.0              0.0                   0.0   \n",
       "in_air                      0.0    0.0              0.0                   0.0   \n",
       "in_docs                     3.0    9.6              0.0                   0.0   \n",
       "in_ndx_out_vol             41.4    6.7             79.2                   0.0   \n",
       "in_ndx_vol_wt              99.1   16.0              0.0                   0.0   \n",
       "in_non_docs                 0.0   50.8              0.0                  79.2   \n",
       "in_surface                  0.0    0.0              0.0                   0.0   \n",
       "out_air                   -38.7    1.3              0.0                   0.0   \n",
       "out_docs                    3.2   10.0              0.0                   0.0   \n",
       "out_ndx_out_vol            36.8    5.9             80.4                   0.0   \n",
       "out_ndx_vol_wt            113.6   18.4              0.0                   0.0   \n",
       "out_non_docs                0.0   51.7              0.0                  80.4   \n",
       "out_surface                 0.0    0.0              0.0                   0.0   \n",
       "\n",
       "impacted_variable  with_sorter_sorter_unit  wt_bag_non_doc  xray_unit  \n",
       "input_variable                                                         \n",
       "at                                     0.0             0.0        0.0  \n",
       "in_air                                 0.0             0.0        0.0  \n",
       "in_docs                                0.0             0.0        0.0  \n",
       "in_ndx_out_vol                         0.0             0.0        0.0  \n",
       "in_ndx_vol_wt                          0.0            73.9        0.0  \n",
       "in_non_docs                           79.2             0.0        0.0  \n",
       "in_surface                             0.0             0.0        0.0  \n",
       "out_air                                0.0             0.0      100.0  \n",
       "out_docs                               0.0             0.0        0.0  \n",
       "out_ndx_out_vol                        0.0             0.0        0.0  \n",
       "out_ndx_vol_wt                         0.0            84.7        0.0  \n",
       "out_non_docs                          80.4             0.0        0.0  \n",
       "out_surface                            0.0             0.0        0.0  \n",
       "\n",
       "[13 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All input variables impacting only manpower_with_sorter, manpower_without_sorter, and cd_unit (no cutoff, one row per input variable):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_variable</th>\n",
       "      <th>impact_cd_unit</th>\n",
       "      <th>impact_manpower_with_sorter</th>\n",
       "      <th>impact_manpower_without_sorter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>out_docs</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>out_non_docs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>out_air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>out_surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>out_ndx_out_vol</td>\n",
       "      <td>26.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>out_ndx_vol_wt</td>\n",
       "      <td>81.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in_docs</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in_non_docs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in_air</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in_surface</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in_ndx_out_vol</td>\n",
       "      <td>29.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in_ndx_vol_wt</td>\n",
       "      <td>71.4</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>at</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.2</td>\n",
       "      <td>-40.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input_variable  impact_cd_unit  impact_manpower_with_sorter  \\\n",
       "0          out_docs             2.3                          7.7   \n",
       "1      out_non_docs             0.0                         39.8   \n",
       "2           out_air             0.0                          0.6   \n",
       "3       out_surface             0.0                          0.0   \n",
       "4   out_ndx_out_vol            26.5                          4.4   \n",
       "5    out_ndx_vol_wt            81.8                         14.5   \n",
       "6           in_docs             2.2                          7.0   \n",
       "7       in_non_docs             0.0                         38.9   \n",
       "8            in_air             0.0                          0.0   \n",
       "9        in_surface             0.0                          0.0   \n",
       "10   in_ndx_out_vol            29.8                          4.8   \n",
       "11    in_ndx_vol_wt            71.4                         12.4   \n",
       "12               at             0.0                        -37.2   \n",
       "\n",
       "    impact_manpower_without_sorter  \n",
       "0                              6.6  \n",
       "1                             48.1  \n",
       "2                              0.5  \n",
       "3                              0.0  \n",
       "4                              3.7  \n",
       "5                             12.3  \n",
       "6                              6.0  \n",
       "7                             47.3  \n",
       "8                              0.0  \n",
       "9                              0.0  \n",
       "10                             4.1  \n",
       "11                            10.5  \n",
       "12                           -40.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Baseline Calculation\n",
    "baseline_df = df.copy()\n",
    "for key in formulas:\n",
    "    baseline_df[key] = baseline_df.apply(lambda row: formulas[key](row), axis=1)\n",
    "baseline_means = baseline_df.mean(numeric_only=True)\n",
    "\n",
    "# 2. Identify input variables (not computed by formulas)\n",
    "all_formula_outputs = set(formulas.keys())\n",
    "input_vars = [col for col in df.columns if col not in all_formula_outputs and pd.api.types.is_numeric_dtype(df[col])]\n",
    "\n",
    "# Remove 'sorter' from input variables as per instruction\n",
    "input_vars = [var for var in input_vars if var != \"sorter\"]\n",
    "\n",
    "# 3. Sensitivity Analysis\n",
    "perturbation = 1  # 100%\n",
    "all_impact_rows = []\n",
    "manpower_impact_dict = {}\n",
    "\n",
    "for var in input_vars:\n",
    "    perturbed_df = df.copy()\n",
    "    perturbed_df[var] = perturbed_df[var] * (1 + perturbation)\n",
    "    for key in formulas:\n",
    "        perturbed_df[key] = perturbed_df.apply(lambda row: formulas[key](row), axis=1)\n",
    "    perturbed_means = perturbed_df.mean(numeric_only=True)\n",
    "    for target in perturbed_means.index:\n",
    "        if var == target:\n",
    "            continue\n",
    "        base = baseline_means[target]\n",
    "        perturbed = perturbed_means[target]\n",
    "        if np.isclose(base, 0):\n",
    "            continue  # Avoid division by zero\n",
    "        impact_percent = ((perturbed - base) / base) * 100\n",
    "        # For all input/impacted pairs, no cutoff\n",
    "        all_impact_rows.append({\n",
    "            \"input_variable\": var,\n",
    "            \"impacted_variable\": target,\n",
    "            \"percent_change\": impact_percent\n",
    "        })\n",
    "        # For only manpower_with_sorter, manpower_without_sorter, and cd_unit as impacted, collect in dict for pivot\n",
    "        if target in [\"manpower_with_sorter\", \"manpower_without_sorter\", \"cd_unit\"]:\n",
    "            if var not in manpower_impact_dict:\n",
    "                manpower_impact_dict[var] = {}\n",
    "            manpower_impact_dict[var][target] = impact_percent\n",
    "\n",
    "# Create a matrix (pivot table) for all input/impacted variable pairs\n",
    "impact_matrix = pd.DataFrame(all_impact_rows).pivot(\n",
    "    index=\"input_variable\", columns=\"impacted_variable\", values=\"percent_change\"\n",
    ")\n",
    "\n",
    "# Limit the matrix numbers to just one decimal places\n",
    "impact_matrix = impact_matrix.round(1)\n",
    "\n",
    "# DataFrame with input variables as rows, and three columns for impact on manpower_with_sorter, manpower_without_sorter, and cd_unit\n",
    "manpower_impact_df = pd.DataFrame.from_dict(manpower_impact_dict, orient='index')\n",
    "manpower_impact_df = manpower_impact_df.rename(columns={\n",
    "    \"manpower_with_sorter\": \"impact_manpower_with_sorter\",\n",
    "    \"manpower_without_sorter\": \"impact_manpower_without_sorter\",\n",
    "    \"cd_unit\": \"impact_cd_unit\"\n",
    "})\n",
    "manpower_impact_df.index.name = \"input_variable\"\n",
    "manpower_impact_df = manpower_impact_df.reset_index()\n",
    "\n",
    "# Limit the matrix numbers to just one decimal places\n",
    "manpower_impact_df = manpower_impact_df.round(1)\n",
    "\n",
    "# Save both DataFrames to CSV\n",
    "impact_matrix.to_csv(\"impact_matrix.csv\")\n",
    "manpower_impact_df.to_csv(\"manpower_impact_df.csv\", index=False)\n",
    "\n",
    "# Display both DataFrames\n",
    "print(\"All input/impacted variable pairs (no cutoff) as a matrix:\")\n",
    "display(impact_matrix)\n",
    "\n",
    "print(\"All input variables impacting only manpower_with_sorter, manpower_without_sorter, and cd_unit (no cutoff, one row per input variable):\")\n",
    "display(manpower_impact_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
